{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "\n",
    "# Define dataset paths\n",
    "train_path = '../Dataset/Train'\n",
    "test_path = '../Dataset/Test'\n",
    "val_path = '../Dataset/Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets using ImageFolder\n",
    "train_dataset = ImageFolder(root=train_path, transform=data_transform)\n",
    "test_dataset = ImageFolder(root=test_path, transform=data_transform)\n",
    "val_dataset = ImageFolder(root=val_path, transform=data_transform)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 64 * 3, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                [-1, 12288]               0\n",
      "            Linear-2                  [-1, 128]       1,572,992\n",
      "              ReLU-3                  [-1, 128]               0\n",
      "           Dropout-4                  [-1, 128]               0\n",
      "            Linear-5                    [-1, 1]             129\n",
      "           Sigmoid-6                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 1,573,121\n",
      "Trainable params: 1,573,121\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.10\n",
      "Params size (MB): 6.00\n",
      "Estimated Total Size (MB): 6.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model, loss function, and optimizer\n",
    "model = SimpleNN()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Move the model to a device (e.g., GPU) if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Print the model summary\n",
    "summary(model, input_size=(3, 64, 64))  # Adjust input_size based on your image dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for generating f1 score\n",
    "def net_f1score(classifier, test_loader):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = classifier(images)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "\n",
    "            true_labels.extend(labels.float().view(-1, 1).cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    true_labels = np.array(true_labels).flatten()\n",
    "    predicted_labels = np.array(predicted_labels).flatten()\n",
    "\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    roc_auc = roc_auc_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return precision, recall, roc_auc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch:  0\n",
      "Epoch 1, Batch 100, Loss: 0.754, Training Accuracy: 58.66%\n",
      "Epoch 1, Batch 200, Loss: 0.647, Training Accuracy: 60.03%\n",
      "Epoch 1, Batch 300, Loss: 0.650, Training Accuracy: 59.59%\n",
      "Epoch 1, Batch 400, Loss: 0.645, Training Accuracy: 60.53%\n",
      "Epoch 1, Batch 500, Loss: 0.635, Training Accuracy: 61.11%\n",
      "Epoch 1, Batch 600, Loss: 0.619, Training Accuracy: 61.92%\n",
      "Epoch 1, Batch 700, Loss: 0.631, Training Accuracy: 62.40%\n",
      "Epoch 1, Batch 800, Loss: 0.609, Training Accuracy: 62.71%\n",
      "Epoch 1, Batch 900, Loss: 0.617, Training Accuracy: 62.94%\n",
      "Epoch 1, Batch 1000, Loss: 0.615, Training Accuracy: 63.33%\n",
      "Epoch 1, Batch 1100, Loss: 0.612, Training Accuracy: 63.54%\n",
      "Epoch 1, Batch 1200, Loss: 0.594, Training Accuracy: 63.85%\n",
      "Epoch 1, Batch 1300, Loss: 0.597, Training Accuracy: 64.05%\n",
      "Epoch 1, Batch 1400, Loss: 0.608, Training Accuracy: 64.18%\n",
      "Epoch 1, Batch 1500, Loss: 0.618, Training Accuracy: 64.26%\n",
      "Epoch 1, Batch 1600, Loss: 0.611, Training Accuracy: 64.37%\n",
      "Epoch 1, Batch 1700, Loss: 0.602, Training Accuracy: 64.48%\n",
      "Epoch 1, Batch 1800, Loss: 0.607, Training Accuracy: 64.59%\n",
      "Epoch 1, Batch 1900, Loss: 0.601, Training Accuracy: 64.68%\n",
      "Epoch 1, Batch 2000, Loss: 0.598, Training Accuracy: 64.80%\n",
      "Epoch 1, Batch 2100, Loss: 0.606, Training Accuracy: 64.90%\n",
      "Epoch 1, Batch 2200, Loss: 0.600, Training Accuracy: 65.00%\n",
      "Epoch 1, Batch 2300, Loss: 0.595, Training Accuracy: 65.12%\n",
      "Epoch 1, Batch 2400, Loss: 0.594, Training Accuracy: 65.17%\n",
      "Epoch 1, Batch 2500, Loss: 0.593, Training Accuracy: 65.27%\n",
      "Epoch 1, Batch 2600, Loss: 0.589, Training Accuracy: 65.35%\n",
      "Epoch 1, Batch 2700, Loss: 0.591, Training Accuracy: 65.37%\n",
      "Epoch 1, Batch 2800, Loss: 0.588, Training Accuracy: 65.44%\n",
      "Epoch 1, Batch 2900, Loss: 0.593, Training Accuracy: 65.52%\n",
      "Epoch 1, Batch 3000, Loss: 0.609, Training Accuracy: 65.53%\n",
      "Epoch 1, Batch 3100, Loss: 0.597, Training Accuracy: 65.55%\n",
      "Epoch 1, Batch 3200, Loss: 0.589, Training Accuracy: 65.63%\n",
      "Epoch 1, Batch 3300, Loss: 0.590, Training Accuracy: 65.71%\n",
      "Epoch 1, Batch 3400, Loss: 0.598, Training Accuracy: 65.75%\n",
      "Epoch 1, Batch 3500, Loss: 0.584, Training Accuracy: 65.84%\n",
      "Epoch 1, Batch 3600, Loss: 0.581, Training Accuracy: 65.90%\n",
      "Epoch 1, Batch 3700, Loss: 0.598, Training Accuracy: 65.92%\n",
      "Epoch 1, Batch 3800, Loss: 0.575, Training Accuracy: 65.99%\n",
      "Epoch 1, Batch 3900, Loss: 0.580, Training Accuracy: 66.05%\n",
      "Epoch 1, Batch 4000, Loss: 0.581, Training Accuracy: 66.11%\n",
      "Epoch 1, Batch 4100, Loss: 0.582, Training Accuracy: 66.19%\n",
      "Epoch 1, Batch 4200, Loss: 0.595, Training Accuracy: 66.20%\n",
      "Epoch 1, Batch 4300, Loss: 0.584, Training Accuracy: 66.25%\n",
      "Validation accuracy: 69.43%\n",
      "Epoch 1, Validation Accuracy: 69.43%\n",
      "Precision: 0.71\n",
      "Recall: 0.66\n",
      "ROC-AUC: 0.69\n",
      "F1 Score: 0.68\n",
      "-------------------------------------------------------------------------\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting epoch: \",epoch)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for entry, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.float().view(-1, 1))   \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute training accuracy\n",
    "        running_loss += loss.item()\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct_train += (predicted == labels.float().view(-1, 1)).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        \n",
    "        if entry % 100 == 99:\n",
    "            print(f'Epoch {epoch+1}, Batch {entry+1}, Loss: {running_loss / 100:.3f}, Training Accuracy: {(correct_train / total_train) * 100:.2f}%')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Model evaluation on validation set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "    # Perform inference or evaluation without tracking gradients\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            predicted = (outputs >= 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.float().view(-1, 1)).sum().item()\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f'Validation accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Validation Accuracy: {accuracy:.2f}%')\n",
    "        \n",
    "    precision, recall, roc_auc, f1 = net_f1score(model, val_loader)\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'ROC-AUC: {roc_auc:.2f}')\n",
    "    print(f'F1 Score: {f1:.2f}')\n",
    "        \n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Save the entire model (architecture and weights)\n",
    "torch.save(model, 'model_ann.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 65.11%\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Lists to store true labels and model predictions\n",
    "true_labels = []\n",
    "model_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs >= 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.float().view(-1, 1)).sum().item()\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        model_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "accuracy = (correct / total) * 100\n",
    "print(f'Test accuracy: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
